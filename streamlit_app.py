import streamlit as st
import os
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain.schema import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter

st.set_page_config(page_title="动手学大模型应用开发", page_icon="🦜🔗")

# ---------- 1. 构造知识库 ----------
# 长文档内容
raw_docs = """
# 第一章 简介
欢迎来到**面向开发者的提示工程**部分，本部分内容基于**吴恩达老师的《Prompt Engineering for Developer》课程**进行编写。《Prompt Engineering for Developer》课程是由**吴恩达老师**与 OpenAI 技术团队成员 **Isa Fulford** 老师合作授课，Isa 老师曾开发过受欢迎的 ChatGPT 检索插件，并且在教授 LLM （Large Language Model， 大语言模型）技术在产品中的应用方面做出了很大贡献。她还参与编写了教授人们使用 Prompt 的 OpenAI cookbook。我们希望通过本模块的学习，与大家分享使用提示词开发 LLM 应用的最佳实践和技巧。

网络上有许多关于提示词（Prompt， 本教程中将保留该术语）设计的材料，例如《30 prompts everyone has to know》之类的文章，这些文章主要集中在 **ChatGPT 的 Web 界面上**，许多人在使用它执行特定的、通常是一次性的任务。但我们认为，对于开发人员，**大语言模型（LLM） 的更强大功能是能通过 API 接口调用，从而快速构建软件应用程序**。实际上，我们了解到 DeepLearning.AI 的姊妹公司 AI Fund 的团队一直在与许多初创公司合作，将这些技术应用于诸多应用程序上。很兴奋能看到 LLM API 能够让开发人员非常快速地构建应用程序。

在本模块，我们将与读者分享提升大语言模型应用效果的各种技巧和最佳实践。书中内容涵盖广泛，包括软件开发提示词设计、文本总结、推理、转换、扩展以及构建聊天机器人等语言模型典型应用场景。我们衷心希望该课程能激发读者的想象力，开发出更出色的语言模型应用。

随着 LLM 的发展，其大致可以分为两种类型，后续称为**基础 LLM** 和**指令微调（Instruction Tuned）LLM**。**基础LLM**是基于文本训练数据，训练出预测下一个单词能力的模型。其通常通过在互联网和其他来源的大量数据上训练，来确定紧接着出现的最可能的词。例如，如果你以“从前，有一只独角兽”作为 Prompt ，基础 LLM 可能会继续预测“她与独角兽朋友共同生活在一片神奇森林中”。但是，如果你以“法国的首都是什么”为 Prompt ，则基础 LLM 可能会根据互联网上的文章，将回答预测为“法国最大的城市是什么？法国的人口是多少？”，因为互联网上的文章很可能是有关法国国家的问答题目列表。

与基础语言模型不同，**指令微调 LLM** 通过专门的训练，可以更好地理解并遵循指令。举个例子，当询问“法国的首都是什么？”时，这类模型很可能直接回答“法国的首都是巴黎”。指令微调 LLM 的训练通常基于预训练语言模型，先在大规模文本数据上进行**预训练**，掌握语言的基本规律。在此基础上进行进一步的训练与**微调（finetune）**，输入是指令，输出是对这些指令的正确回复。有时还会采用**RLHF（reinforcement learning from human feedback，人类反馈强化学习）**技术，根据人类对模型输出的反馈进一步增强模型遵循指令的能力。通过这种受控的训练过程。指令微调 LLM 可以生成对指令高度敏感、更安全可靠的输出，较少无关和损害性内容。因此。许多实际应用已经转向使用这类大语言模型。

因此，本课程将重点介绍针对指令微调 LLM 的最佳实践，我们也建议您将其用于大多数使用场景。当您使用指令微调 LLM 时，您可以类比为向另一个人提供指令（假设他很聪明但不知道您任务的具体细节）。因此，当 LLM 无法正常工作时，有时是因为指令不够清晰。例如，如果您想问“请为我写一些关于阿兰·图灵( Alan Turing )的东西”，在此基础上清楚表明您希望文本专注于他的科学工作、个人生活、历史角色或其他方面可能会更有帮助。另外您还可以指定回答的语调， 来更加满足您的需求，可选项包括*专业记者写作*，或者*向朋友写的随笔*等。

如果你将 LLM 视为一名新毕业的大学生，要求他完成这个任务，你甚至可以提前指定他们应该阅读哪些文本片段来写关于阿兰·图灵的文本，这样能够帮助这位新毕业的大学生更好地完成这项任务。本书的下一章将详细阐释提示词设计的两个关键原则：**清晰明确**和**给予充足思考时间**。

前言
“周志华老师的《机器学习》（西瓜书）是机器学习领域的经典入门教材之一，周老师为了使尽可能多的读 者通过西瓜书对机器学习有所了解, 所以在书中对部分公式的推导细节没有详述，但是这对那些想深究公式推 导细节的读者来说可能“不太友好”，本书旨在对西瓜书里比较难理解的公式加以解析，以及对部分公式补充 具体的推导细节。”
读到这里，大家可能会疑问为啥前面这段话加了引号，因为这只是我们最初的遐想，后来我们了解到，周 老师之所以省去这些推导细节的真实原因是，他本尊认为“理工科数学基础扎实点的大二下学生应该对西瓜书 中的推导细节无困难吧，要点在书里都有了，略去的细节应能脑补或做练习”。所以     本南瓜书只能算是我 等数学渣渣在自学的时候记下来的笔记，希望能够帮助大家都成为一名合格的“理工科数学基础扎实点的大二 下学生”。
使用说明
•  南瓜书的所有内容都是以西瓜书的内容为前置知识进行表述的，所以南瓜书的最佳使用方法是以西瓜书 为主线，遇到自己推导不出来或者看不懂的公式时再来查阅南瓜书；
•  对于初学机器学习的小白，西瓜书第 1 章和第 2 章的公式强烈不建议深究，简单过一下即可，等你学得 有点飘的时候再回来啃都来得及；
•  每个公式的解析和推导我们都力 (zhi) 争 (neng) 以本科数学基础的视角进行讲解，所以超纲的数学知识 我们通常都会以附录和参考文献的形式给出，感兴趣的同学可以继续沿着我们给的资料进行深入学习；
•  若南瓜书里没有你想要查阅的公式，或者你发现南瓜书哪个地方有错误，请毫不犹豫地去我们 GitHub 的 Issues（地址：https://github.com/datawhalechina/pumpkin-book/issues）进行反馈，在对应版块 提交你希望补充的公式编号或者勘误信息，我们通常会在 24 小时以内给您回复，超过 24 小时未回复的 话可以微信联系我们（微信号：at-Sm1les）；
配套视频教程：https://www.bilibili.com/video/BV1Mh411e7VU
在线阅读地址：https://datawhalechina.github.io/pumpkin-book（仅供第 1 版）
最新版 PDF 获取地址：https://github.com/datawhalechina/pumpkin-book/releases

绪论
本章作为“西瓜书”的开篇，主要讲解什么是机器学习以及机器学习的相关数学符号，为后续内容作 铺垫，并未涉及复杂的算法理论，因此阅读本章时只需耐心梳理清楚所有概念和数学符号即可。此外， 在 阅读本章前建议先阅读西瓜书目录前页的《主要符号表》，它能解答在阅读“西瓜书”过程中产生的大部 分对数学符号的疑惑。
本章也作为本书的开篇，笔者在此赘述一下本书的撰写初衷，本书旨在以“过来人”的视角陪读者一 起阅读“西瓜书”，尽力帮读者消除阅读过程中的“数学恐惧”，只要读者学习过《高等数学》、《线性代 数》和《概率论与数理统计》这三门大学必修的数学课， 均能看懂本书对西瓜书中的公式所做的解释和推 导，同时也能体会到这三门数学课在机器学习上碰撞产生的“数学之美”。
1.1    引言
本节以概念理解为主，在此对“算法”和“模型”作补充说明。“算法”是指从数据中学得“模型”的具  体方法，例如后续章节中将会讲述的线性回归、对数几率回归、决策树等。“算法”产出的结果称为“模型”， 通常是具体的函数或者可抽象地看作为函数，例如一元线性回归算法产出的模型即为形如 f (x) = wx + b   的一元一次函数。不过由于严格区分这两者的意义不大， 因此多数文献和资料会将其混用，当遇到这两个  概念时，其具体指代根据上下文判断即可。

1.2    基本术语
本节涉及的术语较多且很多术语都有多个称呼，下面梳理各个术语，并将最常用的称呼加粗标注。
样本：也称为“示例”，是关于一个事件或对象的描述。因为要想让计算机能对现实生活中的事物 进行机器学习，必须先将其抽象为计算机能理解的形式，计算机最擅长做的就是进行数学运算，因此考 虑如何将其抽象为某种数学形式。显然，线性代数中的向量就很适合，因为任何事物都可以由若干“特 征”（或称为“属性”）唯一刻画出来，而向量的各个维度即可用来描述各个特征。例如， 如果用色泽、根 蒂和敲声这 3 个特征来刻画西瓜，那么一个“色泽青绿，根蒂蜷缩，敲声清脆”的西瓜用向量来表示即为x =
(青绿; 蜷缩; 清脆) （向量中的元素用分号“;”分隔时表示此向量为列向量，用逗号“,”分隔时表示为行向量） ，
其中青绿、蜷缩和清脆分别对应为相应特征的取值， 也称为“属性值”。显然， 用中文书写向量的方式不够 “数学”，因此需要将属性值进一步数值化，具体例子参见“西瓜书”第 3 章 3.2。此外，仅靠以上 3 个特 征来刻画西瓜显然不够全面细致， 因此还需要扩展更多维度的特征，一般称此类与特征处理相关的工作为 “特征工程”。
样本空间：也称为“输入空间”或“属性空间”。由于样本采用的是标明各个特征取值的“特征向量” 来进行表示，根据线性代数的知识可知，有向量便会有向量所在的空间，因此称表示样本的特征向量所在	 的空间为样本空间，通常用花式大写的 X 表示。
数据集：数据集通常用集合来表示，令集合 D = {x1, x2, ..., xm } 表示包含 m 个样本的数据集，一般 同一份数据集中的每个样本都含有相同个数的特征，假设此数据集中的每个样本都含有 d 个特征，则第 i 个样本的数学表示为 d 维向量：xi  = (xi1; xi2; ...; xid )，其中 xij  表示样本 xi  在第 j 个属性上的取值。
模型：机器学习的一般流程如下：首先收集若干样本（假设此时有 100 个）， 然后将其分为训练样本 （80 个）和测试样本（20 个），其中 80 个训练样本构成的集合称为“训练集”，20 个测试样本构成的集合 称为“测试集”，接着选用某个机器学习算法，让其在训练集上进行“学习”（或称为“训练”），然后产出 得到“模型”（或称为“学习器”），最后用测试集来测试模型的效果。执行以上流程时， 表示我们已经默认 样本的背后是存在某种潜在的规律， 我们称这种潜在的规律为“真相”或者“真实”，例如样本是一堆好西 瓜和坏西瓜时， 我们默认的便是好西瓜和坏西瓜背后必然存在某种规律能将其区分开。当我们应用某个机 器学习算法来学习时， 产出得到的模型便是该算法所找到的它自己认为的规律，由于该规律通常并不一定


就是所谓的真相，所以也将其称为“假设”。通常机器学习算法都有可配置的参数，同一个机器学习算法， 使用不同的参数配置或者不同的训练集，训练得到的模型通常都不同。
标记：上文提到机器学习的本质就是在学习样本在某个方面的表现是否存在潜在的规律，我们称该方 面的信息为“标记”。例如在学习西瓜的好坏时，“好瓜”和“坏瓜”便是样本的标记。一般第 i 个样本的 标记的数学表示为 yi ，标记所在的空间称为“标记空间”或“输出空间”，数学表示为花式大写的 Y。标 记通常也看作为样本的一部分，因此，一个完整的样本通常表示为 (x, y)。
根据标记的取值类型不同，可将机器学习任务分为以下两类：
• 当标记取值为离散型时，称此类任务为“分类”，例如学习西瓜是好瓜还是坏瓜、学习猫的图片是白 猫还是黑猫等。当分类的类别只有两个时， 称此类任务为“二分类”，通常称其中一个为“正类”，另 一个为“反类”或“负类”；当分类的类别超过两个时，称此类任务为“多分类”。由于标记也属于样 本的一部分，通常也需要参与运算，因此也需要将其数值化，例如对于二分类任务，通常将正类记为 1，反类记为 0，即 Y = {0, 1}。这只是一般默认的做法，具体标记该如何数值化可根据具体机器学 习算法进行相应地调整，例如第 6 章的支持向量机算法则采用的是 Y = {-1, +1}；
• 当标记取值为连续型时，称此类任务为“回归”，例如学习预测西瓜的成熟度、学习预测未来的房价 等。由于是连续型， 因此标记的所有可能取值无法直接罗列，通常只有取值范围，回归任务的标记取 值范围通常是整个实数域 R，即 Y = R。
无论是分类还是回归，机器学习算法最终学得的模型都可以抽象地看作为以样本 x 为自变量，标记 y 为因变量的函数 y = f(x)，即一个从输入空间 X 到输出空间 Y 的映射。例如在学习西瓜的好坏时， 机器 学习算法学得的模型可看作为一个函数 f(x)，给定任意一个西瓜样本 xi  = (青绿; 蜷缩; 清脆)，将其输入 进函数即可计算得到一个输出 yi  = f(xi )，此时得到的 yi   便是模型给出的预测结果，当 yi  取值为 1 时表 明模型认为西瓜 xi  是好瓜，当 yi  取值为 0 时表明模型认为西瓜 xi  是坏瓜。
根据是否有用到标记信息，可将机器学习任务分为以下两类：
• 在模型训练阶段有用到标记信息时，称此类任务为“监督学习”，例如第 3 章的线性模型；
• 在模型训练阶段没用到标记信息时，称此类任务为“无监督学习”，例如第 9 章的聚类。
泛化：由于机器学习的目标是根据已知来对未知做出尽可能准确的判断，因此对未知事物判断的准确  与否才是衡量一个模型好坏的关键，我们称此为“泛化”能力。例如学习西瓜好坏时， 假设训练集中共有 3   个样本：{(x1  = (青绿; 蜷缩), y1  = 好瓜), (x2  = (乌黑; 蜷缩), y2  = 好瓜), (x3  = (浅白; 蜷缩), y3  = 好瓜)}， 同时假设判断西瓜好坏的真相是“只要根蒂蜷缩就是好瓜”，如果应用算法 A 在此训练集上训练得到模型  fa (x)，模型 a 学到的规律是“色泽等于青绿、乌黑或者浅白时， 同时根蒂蜷缩即为好瓜，否则便是坏瓜”， 再应用算法 B 在此训练集上训练得到模型 fb (x)，模型 fb (x) 学到的规律是“只要根蒂蜷缩就是好瓜”，因  此对于一个未见过的西瓜样本 x = (金黄; 蜷缩) 来说，模型 fa (x) 给出的预测结果为“坏瓜”，模型 fb (x)   给出的预测结果为“好瓜”，此时我们称模型 fb (x) 的泛化能力优于模型 fa (x)。
通过以上举例可知，尽管模型 fa (x) 和模型 fb (x) 对训练集学得一样好，即两个模型对训练集中每个 样本的判断都对，但是其所学到的规律是不同的。导致此现象最直接的原因是算法的不同， 但是算法通常 是有限的，可穷举的，尤其是在特定任务场景下可使用的算法更是有限，因此，数据便是导致此现象的另 一重要原因，这也就是机器学习领域常说的“数据决定模型的上限，而算法则是让模型无限逼近上限”, 下 面详细解释此话的含义。
先解释“数据决定模型效果的上限”，其中数据是指从数据量和特征工程两个角度考虑。从数据量的 角度来说，通常数据量越大模型效果越好，因为数据量大即表示累计的经验多，因此模型学习到的经验也 多，自然表现效果越好。例如以上举例中如果训练集中含有相同颜色但根蒂不蜷缩的坏瓜， 模型 a 学到真 相的概率则也会增大；从特征工程的角度来说，通常对特征数值化越合理，特征收集越全越细致，模型效 果通常越好，因为此时模型更易学得样本之间潜在的规律。例如学习区分亚洲人和非洲人时， 此时样本即


为人，在进行特征工程时，如果收集到每个样本的肤色特征，则其他特征例如年龄、身高和体重等便可省 略，因为只需靠肤色这一个特征就足以区分亚洲人和非洲人。
而“算法则是让模型无限逼近上限”是指当数据相关的工作已准备充分时，接下来便可用各种可适用 的算法从数据中学习其潜在的规律进而得到模型，不同的算法学习得到的模型效果自然有高低之分，效果 越好则越逼近上限，即逼近真相。
分布：此处的“分布”指的是概率论中的概率分布，通常假设样本空间服从一个未知“分布”D，而 我们收集到的每个样本都是独立地从该分布中采样得到，即“独立同分布”。通常收集到的样本越多，越 能从样本中反推出 D 的信息，即越接近真相。此假设属于机器学习中的经典假设，在后续学习机器学习 算法过程中会经常用到。

1.3    假设空间
本节的重点是理解“假设空间”和“版本空间”，下面以“房价预测”举例说明。假设现已收集到某地 区近几年的房价和学校数量数据，希望利用收集到的数据训练出能通过学校数量预测房价的模型，具体收 集到的数据如表1-1所示。
表 1-1 房价预测

年份	学校数量	房价
2020	1 所	1 万/m2
2021	2 所	4 万/m2

基于对以上数据的观察以及日常生活经验，不难得出“房价与学校数量成正比”的假设，若将学校数 量设为 x，房价设为 y，则该假设等价表示学校数量和房价呈 y = wx + b 的一元一次函数关系，此时房价 预测问题的假设空间即为“一元一次函数”。确定假设空间以后便可以采用机器学习算法从假设空间中学 得模型，即从一元一次函数空间中学得能满足表1-1中数值关系的某个一元一次函数。学完第 3 章的线性 回归可知当前问题属于一元线性回归问题，根据一元线性回归算法可学得模型为 y = 3x − 2。
除此之外，也可以将问题复杂化，假设学校数量和房价呈 y = wx2  + b 一元二次函数关系，此时问题 变为了线性回归中的多项式回归问题，按照多项式回归算法可学得模型为 y = x2。因此，以表1-1中数据 作为训练集可以有多个假设空间，且在不同的假设空间中都有可能学得能够拟合训练集的模型，我们将所 有能够拟合训练集的模型构成的集合称为“版本空间”。

1.4    归纳偏好
在上一节“房价预测”的例子中，当选用一元线性回归算法时，学得的模型是一元一次函数，当选  用多项式回归算法时，学得的模型是一元二次函数，所以不同的机器学习算法有不同的偏好，我们称为  “归纳偏好”。对于当前房价预测这个例子来说，这两个算法学得的模型哪个更好呢？著名的“奥卡姆剃  刀”原则认为“若有多个假设与观察一致，则选最简单的那个”，但是何为“简单”便见仁见智了，如  果认为函数的幂次越低越简单，则此时一元线性回归算法更好，如果认为幂次越高越简单，则此时多项  式回归算法更好，因此该方法其实并不“简单”，所以并不常用，而最常用的方法则是基于模型在测试  集上的表现来评判模型之间的优劣。测试集是指由训练集之外的样本构成的集合，例如在当前房价预测  问题中，通常会额外留有部分未参与模型训练的数据来对模型进行测试。假设此时额外留有 1 条数据： 	(年份 : 2022年; 学校数量 : 3所; 房价 : 7万/m2 ) 用于测试，模型 y = 3x − 2 的预测结果为 3 * 3 − 2 = 7，预  测正确，模型 y = x2   的预测结果为 32  = 9，预测错误，因此，在当前房价预测问题上，我们认为一元线  性回归算法优于多项式回归算法。


机器学习算法之间没有绝对的优劣之分，只有是否适合当前待解决的问题之分，例如上述测试集中的 数据如果改为 (年份 : 2022年; 学校数量 : 3所; 房价 : 9万/m2 ) 则结论便逆转为多项式回归算法优于一元线 性回归算法。


模型评估与选择
如“西瓜书”前言所述，本章仍属于机器学习基础知识，如果说第 1 章介绍了什么是机器学习及机 器学习的相关数学符号， 那么本章则进一步介绍机器学习的相关概念。具体来说， 介绍内容正如本章名称 “模型评估与选择”所述，讲述的是如何评估模型的优劣和选择最适合自己业务场景的模型。
由于“模型评估与选择”是在模型产出以后进行的下游工作，要想完全吸收本章内容需要读者对模型 有一些基本的认知，因此零基础的读者直接看本章会很吃力，实属正常，在此建议零基础的读者可以简单 泛读本章，仅看能看懂的部分即可，或者直接跳过本章从第 3 章开始看，直至看完第 6 章以后再回头来看 本章便会轻松许多。
2.1    经验误差与过拟合
梳理本节的几个概念。
错误率：E =  ，其中 m 为样本个数，a 为分类错误样本个数。
精度：精度 =1-错误率。
误差：学习器的实际预测输出与样本的真实输出之间的差异。
经验误差：学习器在训练集上的误差，又称为“训练误差”。
泛化误差：学习器在新样本上的误差。
经验误差和泛化误差用于分类问题的定义式可参见“西瓜书”第 12 章的式 (12.1) 和式 (12.2)，接下 来辨析一下以上几个概念。
错误率和精度很容易理解，而且很明显是针对分类问题的。误差的概念更适用于回归问题， 但是，根 据“西瓜书”第 12 章的式 (12.1) 和式 (12.2) 的定义可以看出，在分类问题中也会使用误差的概念，此时 的“差异”指的是学习器的实际预测输出的类别与样本真实的类别是否一致，若一致则“差异”为 0，若 不一致则“差异”为 1，训练误差是在训练集上差异的平均值，而泛化误差则是在新样本（训练集中未出 现过的样本）上差异的平均值。
过拟合是由于模型的学习能力相对于数据来说过于强大，反过来说，欠拟合是因为模型的学习能力相 对于数据来说过于低下。暂且抛开“没有免费的午餐”定理不谈，例如对于“西瓜书”第 1 章图 1.4 中的 训练样本（黑点）来说，用类似于抛物线的曲线 A 去拟合则较为合理，而比较崎岖的曲线 B 相对于训练 样本来说学习能力过于强大，但若仅用一条直线去训练则相对于训练样本来说直线的学习能力过于低下。
2.2    评估方法
本节介绍了 3 种模型评估方法：留出法、交叉验证法、自助法。留出法由于操作简单，因此最常用； 交叉验证法常用于对比同一算法的不同参数配置之间的效果，以及对比不同算法之间的效果；自助法常用  于集成学习（详见“西瓜书”第 8 章的 8.2 节和 8.3 节）产生基分类器。留出法和自助法简单易懂， 在此  不再赘述，下面举例说明交叉验证法的常用方式。
对比同一算法的不同参数配置之间的效果：假设现有数据集 D，且有一个被评估认为适合用于数据集 D 的算法 L，该算法有可配置的参数，假设备选的参数配置方案有两套：方案 a，方案 b。下面通过交叉 验证法为算法 L 筛选出在数据集 D 上效果最好的参数配置方案。以 3 折交叉验证为例，首先按照“西瓜 书”中所说的方法，通过分层采样将数据集 D 划分为 3 个大小相似的互斥子集：D1 , D2 , D3 ，然后分别用 其中 1 个子集作为测试集，其他子集作为训练集，这样就可获得 3 组训练集和测试集：
训练集 1：D1  ∪ D2 ，测试集 1:D3
训练集 2：D1  ∪ D3 ，测试集 2:D2
训练集 3：D2  ∪ D3 ，测试集 3:D1
接下来用算法 L 搭配方案 a 在训练集 1 上进行训练，训练结束后将训练得到的模型在测试集 1 上进 行测试，得到测试结果 1，依此方法再分别通过训练集 2 和测试集 2、训练集 3 和测试集 3 得到测试结果


2 和测试结果 3，最后将 3 次测试结果求平均即可得到算法 L 搭配方案 a 在数据集 D 上的最终效果，记 为 Scorea。同理，按照以上方法也可得到算法 L 搭配方案 b 在数据集 D 上的最终效果 Scoreb ，最后通 过比较 Scorea  和 Scoreb  之间的优劣来确定算法 L 在数据集 D 上效果最好的参数配置方案。
对比不同算法之间的效果：同上述“对比同一算法的不同参数配置之间的效果”中所讲的方法一样， 只需将其中的“算法 L 搭配方案 a”和“算法 L 搭配方案 b”分别换成需要对比的算法 α 和算法 β 即可。
从以上的举例可以看出，交叉验证法本质上是在进行多次留出法，且每次都换不同的子集做测试集， 最终让所有样本均至少做 1 次测试样本。这样做的理由其实很简单，因为一般的留出法只会划分出 1 组  训练集和测试集，仅依靠 1 组训练集和测试集去对比不同算法之间的效果显然不够置信，偶然性太强，因  此要想基于固定的数据集产生多组不同的训练集和测试集，则只有进行多次划分，每次采用不同的子集作  为测试集，也即为交叉验证法。
2.2.1    算法参数（超参数）与模型参数
算法参数是指算法本身的一些参数（也称超参数），例如 k 近邻的近邻个数 k、支持向量机的参数 C （详见“西瓜书”第 6 章式 (6.29)）。算法配置好相应参数后进行训练， 训练结束会得到一个模型，例如支 持向量机最终会得到 w 和 b 的具体数值（此处不考虑核函数），这就是模型参数，模型配置好相应模型参 数后即可对新样本做预测。

2.2.2    验证集
带有参数的算法一般需要从候选参数配置方案中选择相对于当前数据集的最优参数配置方案，例如支 持向量机的参数 C，一般采用的是前面讲到的交叉验证法，但是交叉验证法操作起来较为复杂，实际中更 多采用的是：先用留出法将数据集划分出训练集和测试集，然后再对训练集采用留出法划分出训练集和新 的测试集，称新的测试集为验证集，接着基于验证集的测试结果来调参选出最优参数配置方案，最后将验 证集合并进训练集（训练集数据量够的话也可不合并）， 用选出的最优参数配置在合并后的训练集上重新 训练，再用测试集来评估训练得到的模型的性能。
2.3    性能度量
本节性能度量指标较多，但是一般常用的只有错误率、精度、查准率、查全率、F1 、ROC 和 AUC。

2.3.1    式 (2.2) 到式 (2.7) 的解释
这几个公式简单易懂，几乎不需要额外解释，但是需要补充说明的是式 (2.2)、式 (2.4) 和式 (2.5) 假 设了数据分布为均匀分布，即每个样本出现的概率相同，而式 (2.3)、式 (2.6) 和式 (2.7) 则为更一般的表 达式。此外，在无特别说明的情况下，2.3 节所有公式中的“样例集 D”均默认为非训练集（测试集、验 证集或其他未用于训练的样例集）。
2.3.2    式 (2.8) 和式 (2.9) 的解释
查准率 P：被学习器预测为正例的样例中有多大比例是真正例。
查全率 R：所有正例当中有多大比例被学习器预测为正例。

2.3.3    图 2.3 的解释
P-R 曲线的画法与 ROC 曲线的画法类似，也是通过依次改变模型阈值，然后计算出查准率和查全 率并画出相应坐标点，具体参见“式 (2.20) 的推导”部分的讲解。这里需要说明的是，“西瓜书”中的图 2.3 仅仅是示意图，除了图左侧提到的“现实任务中的 P-R 曲线常是非单调、不平滑的， 在很多局部有上


下波动”以外，通常也不会取到 (1, 0) 点。因为当取到 (1, 0) 点时，此时是将所有样本均判为正例，因此 FN = 0，根据式 (2.8) 可算得查全率为 1，但是此时 TP + FP 为样本总数，根据式 (2.9) 可算得查准率 此时为正例在全体样本中的占比，显然在现实任务中正例的占比通常不为 0，因此 P-R 曲线在现实任务中 通常不会取到 (1, 0) 点。


"""

def build_retriever():
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        st.error("请先设置环境变量 OPENAI_API_KEY")
        st.stop()

    # 切分长文档
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    docs = text_splitter.create_documents([raw_docs])

    embeddings = OpenAIEmbeddings(openai_api_key=api_key)
    vectorstore = FAISS.from_documents(docs, embeddings)
    return vectorstore.as_retriever()

# ---------- 2. 构建问答链 ----------
def get_qa_chain():
    retriever = build_retriever()
    llm = ChatOpenAI(model_name="gpt-4o", temperature=0, openai_api_key=os.getenv("OPENAI_API_KEY"))

    system = (
        "你是一个乐于助人的 AI 助手。\n"
        "请使用下面的上下文回答问题，如果不知道就说“我不知道”。\n\n"
        "{context}"
    )
    prompt = ChatPromptTemplate.from_messages([
        ("system", system),
        ("human", "{question}")
    ])
    chain = (
        {"context": retriever | (lambda docs: "\n\n".join(d.page_content for d in docs)),
         "question": RunnablePassthrough()}
        | prompt
        | llm
        | StrOutputParser()
    )
    return chain

# ---------- 3. Streamlit 主界面 ----------
def main():
    st.markdown("### 🦜🔗 动手学大模型应用开发")

    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "chain" not in st.session_state:
        st.session_state.chain = get_qa_chain()

    msgs = st.container(height=550)
    for role, text in st.session_state.messages:
        msgs.chat_message(role).write(text)

    if prompt := st.chat_input("请输入你的问题"):
        st.session_state.messages.append(("user", prompt))
        msgs.chat_message("user").write(prompt)

        with msgs.chat_message("assistant"):
            response = st.write_stream(st.session_state.chain.stream(prompt))
        st.session_state.messages.append(("assistant", response))

if __name__ == "__main__":
    main()
